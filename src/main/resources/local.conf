include "application.conf"

setl.config {
  spark {
    spark.default.parallelism = "200"
    spark.sql.shuffle.partitions = "200"  # set a bigger value if memory spills
  }
}

categoriesReadConnector {
  storage = "JSON"
  path = "src/main/resources/inputs/categories"
  multiLine = "true"
}

categoriesWriteRepository {
  storage =  "CSV"
  path = "src/main/resources/steps/categories"
  inferSchema = "true"
  delimiter = ";"
  header = "true"
  saveMode = "Overwrite"
}